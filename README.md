# ğŸ“‰ Bias in K-Fold Cross-Validation with Stable Learners

## Understanding & Correcting Risk Estimation Bias in Model Evaluation

### A research & reimplementation project for Statistics for Data Science

## ğŸ“Œ Overview
K-Fold Cross-Validation (K-Fold CV) is a popular technique used to estimate the generalization error of machine learning models. However, standard K-Fold CV may lead to biased risk estimatesâ€”especially when models exhibit algorithmic stability.

This project investigates the bias introduced in K-Fold CV and presents a bias-corrected version designed to improve risk estimation, particularly for stable learning algorithms like SVM.

The project includes:

â— A theoretical overview of K-Fold CV bias

â— A reimplementation in R of both standard and debiased methods

â— A comparison of the two on regression and classification datasets

## ğŸ¯ Objectives
â— Analyze the bias in standard K-Fold cross-validation

â— Implement and compare standard vs. bias-corrected K-Fold CV

â— Use Support Vector Machines (SVM) for model evaluation

â— Test both methods across multiple datasets and folds (K = 3, 4, 5)

â— Quantify error and stability using MSE, hinge loss, and standard deviation


## ğŸ§ª Datasets
Used UCI datasets for both regression and classification tasks:

## ğŸ§® Regression:
â— Real Estate Valuation (REV) â€“ 414 instances, 5 features

â— Energy Efficiency (EE) â€“ 768 instances, 8 features

## ğŸ§  Classification:
â— Raisin Dataset (RS) â€“ 900 samples, 7 attributes

â— BIODEG, AR, IO â€“ Additional benchmark datasets for hinge loss analysis

## âš™ï¸ Technologies & Tools
ğŸ’  Language: R

ğŸ’  Libraries: caret, e1071, boot, readxl

ğŸ’  Models: SVM with radial kernel

ğŸ’  Metrics: Mean Squared Error (MSE), Standard Deviation, Hinge Loss

## ğŸ§  Methodology
â¤ Standard K-Fold CV:
â¤ Split dataset into K folds

â¤ For each fold:

â¤ Train on K-1 folds

â¤ Test on the remaining fold

â¤ Average the loss/error across all folds

â¤ Bias-Corrected K-Fold CV:
â¤ Incorporates stability coefficients (Î²) of the learning algorithm

â¤ Adds a correction term to reduce the downward bias in risk estimates

â¤ Produces more accurate generalization error, especially for stable learners

## ğŸ“ˆ Key Results
âœ… Regression â€“ MSE Comparison

âœ… Dataset	K	Standard CV	Bias-Corrected CV
âœ… REV	3	66.10	64.42
âœ… EE	5	2.90	3.18
âœ… Bias-corrected K-Fold gives slightly higher but more accurate estimates of error

âœ… Classification â€“ Hinge Loss
âœ… Bias-corrected CV produced lower hinge loss across all folds and datasets

âœ… Improved classification performance observed in stable learners

## ğŸ“Š Visual Analysis
ğŸ’  Plotted training vs. testing loss for both methods

ğŸ’  Visualized bias corrections across folds

ğŸ’  Comparative analysis shows bias reduction and risk accuracy improvement

## âœ… Key Takeaways
ğŸ’  Standard K-Fold CV underestimates risk when applied to stable learners

ğŸ’  Bias-corrected version improves risk reliability, especially in small datasets

ğŸ’  Helps practitioners make more informed decisions on model performance

S\ğŸ’  uitable for use in model evaluation pipelines and academic research

## ğŸ‘¥ Authors
âœ¨ Amir Hassan


## ğŸ“« Contact
âœ¨ ğŸ“§ amirhassanunipi29@gmail.com


